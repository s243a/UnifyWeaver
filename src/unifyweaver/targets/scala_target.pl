% SPDX-License-Identifier: MIT OR Apache-2.0
% Copyright (c) 2025 John William Creighton (s243a)
%
% scala_target.pl - Scala Target for UnifyWeaver
% Generates Scala programs for record/field processing
% Supports streaming with LazyList, pattern matching, and case classes

:- encoding(utf8).

:- module(scala_target, [
    compile_predicate_to_scala/3,     % +Predicate, +Options, -ScalaCode
    compile_scala_pipeline/3,         % +Predicates, +Options, -ScalaCode
    generate_sbt_build/2,             % +Options, -BuildFile
    write_scala_program/2,            % +ScalaCode, +FilePath
    init_scala_target/0,              % Initialize Scala target
    test_scala_pipeline_mode/0        % Test pipeline mode
]).

:- use_module(library(lists)).

% Binding system integration
:- use_module('../core/binding_registry').

% Track required imports
:- dynamic required_scala_import/1.

%% init_scala_target
init_scala_target :-
    retractall(required_scala_import(_)).

%% clear_scala_imports
clear_scala_imports :-
    retractall(required_scala_import(_)).

%% collect_scala_import(+Import)
collect_scala_import(Import) :-
    (   required_scala_import(Import)
    ->  true
    ;   assertz(required_scala_import(Import))
    ).

%% get_scala_imports(-Imports)
get_scala_imports(Imports) :-
    findall(I, required_scala_import(I), Imports).

%% format_scala_imports(+Imports, -FormattedStr)
format_scala_imports([], "").
format_scala_imports(Imports, FormattedStr) :-
    Imports \= [],
    sort(Imports, UniqueImports),
    findall(Formatted,
        (   member(Import, UniqueImports),
            format(string(Formatted), "import ~w~n", [Import])
        ),
        FormattedList),
    atomic_list_concat(FormattedList, '', FormattedStr).

%% ============================================
%% PUBLIC API
%% ============================================

%% compile_predicate_to_scala(+Predicate, +Options, -ScalaCode)
compile_predicate_to_scala(PredIndicator, Options, ScalaCode) :-
    (   PredIndicator = _Module:Pred/Arity
    ->  true
    ;   PredIndicator = Pred/Arity
    ),
    format('=== Compiling ~w/~w to Scala ===~n', [Pred, Arity]),

    clear_scala_imports,

    % Check mode
    (   option(generator_mode(true), Options)
    ->  format('  Mode: Generator (LazyList/Iterator)~n'),
        compile_generator_mode_scala(Pred, Arity, Options, ScalaCode)
    ;   option(pipeline_input(true), Options)
    ->  format('  Mode: Pipeline (streaming)~n'),
        compile_pipeline_mode_scala(Pred, Arity, Options, ScalaCode)
    ;   format('  Mode: Simple predicate~n'),
        compile_simple_mode_scala(Pred, Arity, Options, ScalaCode)
    ).

%% ============================================
%% SIMPLE MODE
%% ============================================

compile_simple_mode_scala(Pred, Arity, _Options, ScalaCode) :-
    format(string(ScalaCode),
"// Generated by UnifyWeaver Scala Target
// Predicate: ~w/~w

package generated

object ~wApp {
  def ~w(args: Any*): Option[Any] = {
    // TODO: Implement ~w logic
    None
  }

  def main(args: Array[String]): Unit = {
    // TODO: Add main logic
  }
}
", [Pred, Arity, Pred, Pred, Pred]).

%% ============================================
%% GENERATOR MODE (Scala's LazyList/Iterator)
%% ============================================

compile_generator_mode_scala(Pred, Arity, Options, ScalaCode) :-
    collect_scala_import('scala.util.parsing.json.JSON'),
    collect_scala_import('scala.io.Source'),
    collect_scala_import('scala.collection.immutable.LazyList'),
    
    option(package(Package), Options, generated),
    
    % Gather clauses
    functor(Head, Pred, Arity),
    findall((Head, Body), clause(Head, Body), Clauses),
    
    % Generate generator body
    (   Clauses == []
    ->  GeneratorBody = "      // No clauses found - yield input unchanged\n      LazyList(record)"
    ;   generate_generator_body_scala(Clauses, GeneratorBody)
    ),
    
    get_scala_imports(ImportList),
    format_scala_imports(ImportList, ImportsStr),
    
    upcase_atom_first(Pred, CapPred),
    
    format(string(ScalaCode),
"// Generated by UnifyWeaver Scala Target - Generator Mode
// Predicate: ~w/~w
// Uses Scala's LazyList for lazy evaluation

package ~w

~w

/**
 * Generator for ~w predicate.
 * Uses LazyList for lazy, memory-efficient processing.
 */
object ~wGenerator {

  type Record = Map[String, Any]

  /**
   * Process a single record, yielding zero or more results.
   * @param record Input record
   * @return LazyList of output records
   */
  def process(record: Record): LazyList[Record] = {
~w
  }

  /**
   * Process all records, flattening results.
   */
  def processAll(records: LazyList[Record]): LazyList[Record] =
    records.flatMap(process)

  /**
   * Run the generator pipeline.
   */
  def runPipeline(): Unit = {
    val lines = Source.stdin.getLines()
    
    val inputRecords: LazyList[Record] = LazyList.from(
      lines.filter(_.nonEmpty).flatMap { line =>
        parseJson(line)
      }
    )
    
    processAll(inputRecords).foreach { result =>
      println(toJson(result))
    }
  }

  private def parseJson(s: String): Option[Record] = {
    JSON.parseFull(s).collect { case m: Map[String, Any] @unchecked => m }
  }

  private def toJson(m: Record): String = {
    m.map { case (k, v) => s\"\"\"\"$k\":${valueToJson(v)}\"\"\" }.mkString(\"{\", \",\", \"}\")
  }

  private def valueToJson(v: Any): String = v match {
    case s: String => s\"\"\"\"$s\"\"\"\"
    case n: Number => n.toString
    case b: Boolean => b.toString
    case null => \"null\"
    case m: Map[_, _] => toJson(m.asInstanceOf[Record])
    case _ => s\"\"\"\"${v.toString}\"\"\"\"
  }

  def main(args: Array[String]): Unit = runPipeline()
}
", [Pred, Arity, Package, ImportsStr, Pred, CapPred, GeneratorBody]).

%% generate_generator_body_scala(+Clauses, -Code)
generate_generator_body_scala(Clauses, Code) :-
    Clauses = [(Head, _)|_],
    functor(Head, Name, _),
    (   is_recursive_predicate_scala(Name, Clauses)
    ->  partition(is_recursive_clause_scala(Name), Clauses, RecClauses, BaseClauses),
        compile_generator_recursive_scala(Name, BaseClauses, RecClauses, Code)
    ;   findall(ClauseCode, 
            (member((H, B), Clauses), translate_generator_clause_scala(H, B, ClauseCode)),
            ClauseCodes),
        atomic_list_concat(ClauseCodes, '\n', Code)
    ).

translate_generator_clause_scala(Head, Body, Code) :-
    Head =.. [_Pred|Args],
    generate_input_extraction_scala(Args, InputCode),
    (   Body == true
    ->  BodyCode = "      // Fact - unconditional"
    ;   translate_generator_body_scala(Body, BodyCode)
    ),
    format(string(Code), "~w\n~w\n      LazyList(record)", [InputCode, BodyCode]).

translate_generator_body_scala((Goal, Rest), Code) :-
    !,
    translate_generator_goal_scala(Goal, Code1),
    translate_generator_body_scala(Rest, Code2),
    format(string(Code), "~w\n~w", [Code1, Code2]).
translate_generator_body_scala(Goal, Code) :-
    translate_generator_goal_scala(Goal, Code).

translate_generator_goal_scala(>(X, Y), Code) :-
    !, expr_to_scala(X, SX), expr_to_scala(Y, SY),
    format(string(Code), "      if (!(~w > ~w)) return LazyList.empty", [SX, SY]).

translate_generator_goal_scala(<(X, Y), Code) :-
    !, expr_to_scala(X, SX), expr_to_scala(Y, SY),
    format(string(Code), "      if (!(~w < ~w)) return LazyList.empty", [SX, SY]).

translate_generator_goal_scala(=:=(X, Y), Code) :-
    !, expr_to_scala(X, SX), expr_to_scala(Y, SY),
    format(string(Code), "      if (~w != ~w) return LazyList.empty", [SX, SY]).

translate_generator_goal_scala(true, "      // true") :- !.

translate_generator_goal_scala(Goal, Code) :-
    format(string(Code), "      // TODO: ~w", [Goal]).

compile_generator_recursive_scala(Name, BaseClauses, _RecClauses, Code) :-
    (   BaseClauses = [(BaseHead, _)|_]
    ->  generate_base_condition_scala(BaseHead, BaseCondition)
    ;   BaseCondition = "false"
    ),
    
    format(string(Code),
"      // Recursive generator: ~w
      def iterate(current: Record, depth: Int): LazyList[Record] = {
        if (depth > 10000) {
          System.err.println(s\"Warning: Max depth exceeded for ~w\")
          LazyList.empty
        } else if (~w) {
          LazyList(current)
        } else {
          current #:: iterate(current, depth + 1)
        }
      }
      iterate(record, 0)", [Name, Name, BaseCondition]).

%% ============================================
%% PIPELINE MODE
%% ============================================

compile_pipeline_mode_scala(Pred, Arity, Options, ScalaCode) :-
    collect_scala_import('scala.util.parsing.json.JSON'),
    collect_scala_import('scala.io.Source'),
    
    option(package(Package), Options, generated),
    
    functor(Head, Pred, Arity),
    findall((Head, Body), clause(Head, Body), Clauses),
    
    (   Clauses == []
    ->  ProcessCode = "    // No clauses found - pass through\n    Some(record)"
    ;   generate_pipeline_process_scala(Clauses, ProcessCode)
    ),
    
    get_scala_imports(ImportList),
    format_scala_imports(ImportList, ImportsStr),
    
    upcase_atom_first(Pred, CapPred),
    
    format(string(ScalaCode),
"// Generated by UnifyWeaver Scala Target - Pipeline Mode
// Predicate: ~w/~w

package ~w

~w

/**
 * Pipeline processor for ~w predicate.
 */
object ~wPipeline {

  type Record = Map[String, Any]

  /**
   * Process a single input record.
   * @return Some(record) to keep, None to filter out
   */
  def process(record: Record): Option[Record] = {
~w
  }

  def runPipeline(): Unit = {
    Source.stdin.getLines()
      .filter(_.nonEmpty)
      .flatMap { line =>
        parseJson(line).flatMap(process)
      }
      .foreach { result =>
        println(toJson(result))
      }
  }

  private def parseJson(s: String): Option[Record] = {
    JSON.parseFull(s).collect { case m: Map[String, Any] @unchecked => m }
  }

  private def toJson(m: Record): String = {
    m.map { case (k, v) => s\"\"\"\"$k\":${valueToJson(v)}\"\"\" }.mkString(\"{\", \",\", \"}\")
  }

  private def valueToJson(v: Any): String = v match {
    case s: String => s\"\"\"\"$s\"\"\"\"
    case n: Number => n.toString
    case b: Boolean => b.toString
    case null => \"null\"
    case m: Map[_, _] => toJson(m.asInstanceOf[Record])
    case _ => s\"\"\"\"${v.toString}\"\"\"\"
  }

  def main(args: Array[String]): Unit = runPipeline()
}
", [Pred, Arity, Package, ImportsStr, Pred, CapPred, ProcessCode]).

%% upcase_atom_first(+Atom, -CapAtom)
upcase_atom_first(Atom, CapAtom) :-
    atom_codes(Atom, [H|T]),
    (   H >= 97, H =< 122
    ->  H2 is H - 32,
        atom_codes(CapAtom, [H2|T])
    ;   CapAtom = Atom
    ).

%% generate_pipeline_process_scala(+Clauses, -Code)
generate_pipeline_process_scala([], "    Some(record)").
generate_pipeline_process_scala(Clauses, Code) :-
    Clauses \= [],
    Clauses = [(Head, _)|_],
    functor(Head, Name, _),
    (   is_recursive_predicate_scala(Name, Clauses)
    ->  partition(is_recursive_clause_scala(Name), Clauses, RecClauses, BaseClauses),
        compile_tail_recursive_scala(Name, BaseClauses, RecClauses, Code)
    ;   findall(ClauseCode, 
            (member((H, B), Clauses), translate_clause_scala(H, B, ClauseCode)),
            ClauseCodes),
        atomic_list_concat(ClauseCodes, '\n', Code)
    ).

%% ============================================
%% RECURSION DETECTION
%% ============================================

is_recursive_predicate_scala(Name, Clauses) :-
    member((_, Body), Clauses),
    contains_recursive_call_scala(Body, Name).

is_recursive_clause_scala(Name, (_, Body)) :-
    contains_recursive_call_scala(Body, Name).

contains_recursive_call_scala(Body, Name) :-
    extract_goal_scala(Body, Goal),
    functor(Goal, Name, _),
    !.

extract_goal_scala(Goal, Goal) :-
    compound(Goal),
    \+ Goal = (_,_),
    \+ Goal = (_;_).
extract_goal_scala((A, _), Goal) :- extract_goal_scala(A, Goal).
extract_goal_scala((_, B), Goal) :- extract_goal_scala(B, Goal).

%% ============================================
%% TAIL RECURSION (Scala's @tailrec)
%% ============================================

compile_tail_recursive_scala(Name, BaseClauses, _RecClauses, Code) :-
    (   BaseClauses = [(BaseHead, _)|_]
    ->  generate_base_condition_scala(BaseHead, BaseCondition)
    ;   BaseCondition = "false"
    ),
    
    format(string(Code),
"    // Tail-recursive predicate: ~w
    import scala.annotation.tailrec
    
    @tailrec
    def iterate(current: Record, depth: Int): Option[Record] = {
      if (depth > 10000) {
        System.err.println(s\"Warning: Max depth for ~w\")
        Some(current)
      } else if (~w) {
        Some(current)
      } else {
        iterate(current, depth + 1)
      }
    }
    iterate(record, 0)", [Name, Name, BaseCondition]).

generate_base_condition_scala(Head, Condition) :-
    Head =.. [_|Args],
    (   Args = [Arg|_],
        (   number(Arg)
        ->  format(string(Condition), "current.get(\"arg0\").contains(~w)", [Arg])
        ;   atom(Arg)
        ->  format(string(Condition), "current.get(\"arg0\").contains(\"~w\")", [Arg])
        ;   Condition = "false"
        )
    ;   Condition = "false"
    ).

%% ============================================
%% CLAUSE TRANSLATION
%% ============================================

translate_clause_scala(Head, Body, Code) :-
    Head =.. [_Pred|Args],
    generate_input_extraction_scala(Args, InputCode),
    (   Body == true
    ->  BodyCode = "    // Fact - no conditions"
    ;   translate_body_scala(Body, BodyCode)
    ),
    format(string(Code), "~w\n~w\n    Some(record)", [InputCode, BodyCode]).

generate_input_extraction_scala(Args, Code) :-
    findall(Line, (
        nth0(I, Args, Arg),
        (   var(Arg)
        ->  format(string(Line), "    val arg~w = record.get(\"arg~w\")", [I, I])
        ;   format(string(Line), "    // arg~w = ~w (constant)", [I, Arg])
        )
    ), Lines),
    atomic_list_concat(Lines, '\n', Code).

%% ============================================
%% BODY TRANSLATION
%% ============================================

translate_body_scala((Goal, Rest), Code) :-
    !,
    translate_goal_scala(Goal, Code1),
    translate_body_scala(Rest, Code2),
    format(string(Code), "~w\n~w", [Code1, Code2]).
translate_body_scala(Goal, Code) :-
    translate_goal_scala(Goal, Code).

translate_goal_scala(>(X, Y), Code) :-
    !, expr_to_scala(X, SX), expr_to_scala(Y, SY),
    format(string(Code), "    if (!(~w > ~w)) return None", [SX, SY]).

translate_goal_scala(<(X, Y), Code) :-
    !, expr_to_scala(X, SX), expr_to_scala(Y, SY),
    format(string(Code), "    if (!(~w < ~w)) return None", [SX, SY]).

translate_goal_scala(>=(X, Y), Code) :-
    !, expr_to_scala(X, SX), expr_to_scala(Y, SY),
    format(string(Code), "    if (!(~w >= ~w)) return None", [SX, SY]).

translate_goal_scala(=<(X, Y), Code) :-
    !, expr_to_scala(X, SX), expr_to_scala(Y, SY),
    format(string(Code), "    if (!(~w <= ~w)) return None", [SX, SY]).

translate_goal_scala(=:=(X, Y), Code) :-
    !, expr_to_scala(X, SX), expr_to_scala(Y, SY),
    format(string(Code), "    if (~w != ~w) return None", [SX, SY]).

translate_goal_scala(=\\=(X, Y), Code) :-
    !, expr_to_scala(X, SX), expr_to_scala(Y, SY),
    format(string(Code), "    if (~w == ~w) return None", [SX, SY]).

translate_goal_scala(is(Var, Expr), Code) :-
    !,
    var_to_scala(Var, ScalaVar),
    expr_to_scala(Expr, ScalaExpr),
    format(string(Code), "    val ~w = ~w", [ScalaVar, ScalaExpr]).

translate_goal_scala(true, "    // true") :- !.

translate_goal_scala(Goal, Code) :-
    format(string(Code), "    // TODO: ~w", [Goal]).

%% ============================================
%% HELPER PREDICATES
%% ============================================

var_to_scala(Var, ScalaVar) :-
    (   var(Var)
    ->  term_to_atom(Var, VarAtom),
        format(atom(ScalaVar), "var_~w", [VarAtom])
    ;   Var = '$VAR'(N)
    ->  format(atom(ScalaVar), "v~w", [N])
    ;   term_to_atom(Var, ScalaVar)
    ).

expr_to_scala(Expr, ScalaExpr) :-
    (   number(Expr)
    ->  format(atom(ScalaExpr), "~w", [Expr])
    ;   var(Expr)
    ->  var_to_scala(Expr, ScalaExpr)
    ;   Expr = '$VAR'(N)
    ->  format(atom(ScalaExpr), "v~w", [N])
    ;   Expr = X + Y
    ->  expr_to_scala(X, SX), expr_to_scala(Y, SY),
        format(atom(ScalaExpr), "(~w + ~w)", [SX, SY])
    ;   Expr = X - Y
    ->  expr_to_scala(X, SX), expr_to_scala(Y, SY),
        format(atom(ScalaExpr), "(~w - ~w)", [SX, SY])
    ;   Expr = X * Y
    ->  expr_to_scala(X, SX), expr_to_scala(Y, SY),
        format(atom(ScalaExpr), "(~w * ~w)", [SX, SY])
    ;   Expr = X / Y
    ->  expr_to_scala(X, SX), expr_to_scala(Y, SY),
        format(atom(ScalaExpr), "(~w / ~w)", [SX, SY])
    ;   Expr = X mod Y
    ->  expr_to_scala(X, SX), expr_to_scala(Y, SY),
        format(atom(ScalaExpr), "(~w % ~w)", [SX, SY])
    ;   format(atom(ScalaExpr), "~w", [Expr])
    ).

%% ============================================
%% SBT BUILD GENERATION
%% ============================================

generate_sbt_build(Options, BuildFile) :-
    option(scala_version(ScalaVersion), Options, '3.3.1'),
    option(name(Name), Options, 'pipeline'),
    option(version(Version), Options, '0.1.0'),
    
    format(string(BuildFile),
"// Generated by UnifyWeaver Scala Target

name := \"~w\"
version := \"~w\"
scalaVersion := \"~w\"

libraryDependencies ++= Seq(
  \"org.scala-lang.modules\" %% \"scala-parser-combinators\" % \"2.3.0\"
)

// Enable Scala 3 features
scalacOptions ++= Seq(
  \"-deprecation\",
  \"-feature\",
  \"-unchecked\"
)
", [Name, Version, ScalaVersion]).

%% ============================================
%% UTILITY PREDICATES
%% ============================================

write_scala_program(ScalaCode, FilePath) :-
    open(FilePath, write, Stream),
    write(Stream, ScalaCode),
    close(Stream),
    format('Written Scala program to: ~w~n', [FilePath]).

option(Option, Options, _Default) :-
    member(Option, Options), !.
option(Option, _Options, Default) :-
    Option =.. [_, Default].

compile_scala_pipeline(_Steps, _Options, Code) :-
    Code = "// Multi-step Scala pipeline - use compile_predicate_to_scala for now".

%% ============================================
%% TESTS
%% ============================================

test_scala_pipeline_mode :-
    format('~n=== Testing Scala Pipeline Mode ===~n~n'),
    
    format('Test 1: Basic pipeline generation~n'),
    compile_predicate_to_scala(test_pred/2, [pipeline_input(true)], Code1),
    (   sub_atom(Code1, _, _, _, 'runPipeline')
    ->  format('  [PASS] Generated pipeline code~n')
    ;   format('  [FAIL] Missing pipeline code~n')
    ),
    
    format('~nTest 2: Scala pattern matching~n'),
    (   sub_atom(Code1, _, _, _, 'case')
    ->  format('  [PASS] Uses pattern matching~n')
    ;   format('  [INFO] No pattern matching in this mode~n')
    ),
    
    format('~nTest 3: Option type~n'),
    (   sub_atom(Code1, _, _, _, 'Option[')
    ->  format('  [PASS] Uses Option type~n')
    ;   format('  [FAIL] Missing Option type~n')
    ),
    
    format('~nTest 4: Generator mode~n'),
    compile_predicate_to_scala(test_gen/2, [generator_mode(true)], Code2),
    (   sub_atom(Code2, _, _, _, 'LazyList')
    ->  format('  [PASS] Uses LazyList~n')
    ;   format('  [FAIL] Missing LazyList~n')
    ),
    
    format('~nTest 5: SBT build generation~n'),
    generate_sbt_build([scala_version('3.3.1')], BuildCode),
    (   sub_atom(BuildCode, _, _, _, 'scalaVersion')
    ->  format('  [PASS] Generated SBT build~n')
    ;   format('  [FAIL] Invalid SBT build~n')
    ),
    
    format('~n=== Scala Pipeline Mode Tests Complete ===~n').
