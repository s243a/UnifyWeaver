# Proposal: Compiling Smoothing Policy with UnifyWeaver

## Overview

This proposal describes how UnifyWeaver can compile declarative smoothing policies from Prolog to target languages (Python, Go, Rust). The smoothing policy determines which technique to apply at each level of a hierarchical cluster structure, optimizing the accuracy/cost tradeoff.

## Background: The Smoothing Problem

### Why Smoothing?

In semantic search with LDA projection, each cluster learns a projection matrix W that maps questions toward answers. The challenge:

- **Sparse clusters**: Most have 1-3 questions but d=64+ dimensions
- **Underdetermined system**: Q @ W = A has infinitely many solutions
- **Overfitting**: Per-cluster W matrices memorize training data

Smoothing regularizes W matrices by leveraging similarity between clusters.

### Available Techniques

We've implemented four smoothing approaches, each with different characteristics:

| Technique | Accuracy | Training Cost | Inference Cost | Best For |
|-----------|----------|---------------|----------------|----------|
| Baseline (MultiHeadLDA) | 94% P@1 | O(N·d) | O(N·d) | Latency-critical |
| FFT Smoothing | 99% P@1 | O(N·d³) | O(N·d²) | Production default |
| SmoothingBasis | 94% P@1 | O(iter·N·K²·d²) | O(N·K·d²) | Interpretability |
| Hierarchical (old) | 85% P@1 | O(N²·d + ...) | O(levels·...) | Not recommended |

### The Insight: Hierarchical Combination

No single technique is optimal everywhere. The key insight:

1. **FFT** excels at scale (N > 30 clusters) with O(N log N) ordering
2. **Basis methods** excel in the "sweet spot" (10-50 clusters) with interpretable structure
3. **Baseline** is sufficient for tiny segments or already-distinguishable clusters

By combining techniques hierarchically based on the tree structure created by FFT's MST+DFS ordering, we can optimize both accuracy and cost.

## The Declarative Policy

### Why Prolog?

The decision of which technique to apply at each node depends on multiple factors:

- Cluster count at that node
- Depth in the tree
- Data quality (avg pairs per cluster)
- Distinguishability (can we already tell clusters apart?)

These rules are naturally expressed declaratively:

```prolog
%% Large nodes at shallow depths -> FFT
recommended_technique(NodeId, fft) :-
    node(NodeId, ClusterCount, _, Depth, _),
    ClusterCount >= 30,
    Depth < 3.

%% Medium nodes with good data -> basis_k8
recommended_technique(NodeId, basis_k8) :-
    node(NodeId, ClusterCount, _, Depth, AvgPairs),
    ClusterCount >= 10, ClusterCount =< 50,
    Depth >= 1,
    AvgPairs >= 2.

%% Already distinguishable -> skip refinement
recommended_technique(NodeId, baseline) :-
    clusters_distinguishable(NodeId).
```

### Current Implementation

The policy is defined in `src/unifyweaver/core/lda_smoothing_policy.pl` with:

1. **Node facts**: `node(Id, ClusterCount, TotalPairs, Depth, AvgPairs)`
2. **Technique rules**: `recommended_technique(NodeId, Technique)`
3. **Refinement rules**: `refinement_needed(NodeId)`
4. **Distinguishability**: `clusters_distinguishable(NodeId)`

A manual Python translation exists in `smoothing_planner.py` as `_python_fallback_plan()`.

## Compilation Target

### Goal

UnifyWeaver should compile `smoothing_policy.pl` to native target code, eliminating the need for:
- Runtime Prolog interpreter
- Manual Python translation
- Maintenance of parallel implementations

### Input: Prolog Policy

```prolog
:- module(lda_smoothing_policy, [
    recommended_technique/2,
    refinement_needed/1,
    clusters_distinguishable/1
]).

%% Thresholds (could be configurable)
fft_threshold(30).
basis_sweet_spot(10, 50).
distinguish_threshold(0.3).

%% Main decision rules
recommended_technique(NodeId, fft) :-
    node(NodeId, ClusterCount, _, Depth, _),
    fft_threshold(Threshold),
    ClusterCount >= Threshold,
    Depth < 3.

recommended_technique(NodeId, basis_k8) :-
    node(NodeId, ClusterCount, _, Depth, AvgPairs),
    basis_sweet_spot(MinC, MaxC),
    ClusterCount >= MinC,
    ClusterCount =< MaxC,
    Depth >= 1,
    AvgPairs >= 2.

recommended_technique(NodeId, baseline) :-
    clusters_distinguishable(NodeId).

recommended_technique(NodeId, baseline) :-
    node(NodeId, ClusterCount, _, _, _),
    ClusterCount < 5.

%% Distinguishability check
clusters_distinguishable(NodeId) :-
    similarity_score(NodeId, Score),
    distinguish_threshold(Threshold),
    Score < Threshold.

%% Refinement decision
refinement_needed(NodeId) :-
    node(NodeId, ClusterCount, _, Depth, _),
    ClusterCount > 10,
    Depth < 4,
    similarity_score(NodeId, Score),
    Score > 0.7.
```

### Output: Python Target

```python
# Generated by UnifyWeaver from lda_smoothing_policy.pl

FFT_THRESHOLD = 30
BASIS_SWEET_SPOT = (10, 50)
DISTINGUISH_THRESHOLD = 0.3

def recommended_technique(node_id: str, nodes: dict, similarities: dict) -> str:
    node = nodes[node_id]
    cluster_count = node['cluster_count']
    depth = node['depth']
    avg_pairs = node['avg_pairs']
    similarity = similarities.get(node_id, 0.5)

    # Rule 1: Large clusters at shallow depths -> FFT
    if cluster_count >= FFT_THRESHOLD and depth < 3:
        return 'fft'

    # Rule 2: Medium clusters -> basis_k8
    if (BASIS_SWEET_SPOT[0] <= cluster_count <= BASIS_SWEET_SPOT[1]
            and depth >= 1 and avg_pairs >= 2):
        return 'basis_k8'

    # Rule 3: Already distinguishable -> baseline
    if similarity < DISTINGUISH_THRESHOLD:
        return 'baseline'

    # Rule 4: Small clusters -> baseline
    if cluster_count < 5:
        return 'baseline'

    # Fallback
    return 'basis_k4' if cluster_count >= 5 else 'baseline'


def refinement_needed(node_id: str, nodes: dict, similarities: dict) -> bool:
    node = nodes[node_id]
    similarity = similarities.get(node_id, 0.5)

    return (node['cluster_count'] > 10 and
            node['depth'] < 4 and
            similarity > 0.7)
```

### Output: Go Target

```go
// Generated by UnifyWeaver from lda_smoothing_policy.pl

package smoothing

const (
    FFTThreshold       = 30
    BasisSweetSpotMin  = 10
    BasisSweetSpotMax  = 50
    DistinguishThreshold = 0.3
)

type Node struct {
    ID           string
    ClusterCount int
    Depth        int
    AvgPairs     float64
}

func RecommendedTechnique(node Node, similarity float64) string {
    // Rule 1: Large clusters at shallow depths -> FFT
    if node.ClusterCount >= FFTThreshold && node.Depth < 3 {
        return "fft"
    }

    // Rule 2: Medium clusters -> basis_k8
    if node.ClusterCount >= BasisSweetSpotMin &&
       node.ClusterCount <= BasisSweetSpotMax &&
       node.Depth >= 1 && node.AvgPairs >= 2 {
        return "basis_k8"
    }

    // Rule 3: Already distinguishable -> baseline
    if similarity < DistinguishThreshold {
        return "baseline"
    }

    // Rule 4: Small clusters -> baseline
    if node.ClusterCount < 5 {
        return "baseline"
    }

    // Fallback
    if node.ClusterCount >= 5 {
        return "basis_k4"
    }
    return "baseline"
}

func RefinementNeeded(node Node, similarity float64) bool {
    return node.ClusterCount > 10 &&
           node.Depth < 4 &&
           similarity > 0.7
}
```

### Output: Rust Target

```rust
// Generated by UnifyWeaver from lda_smoothing_policy.pl

const FFT_THRESHOLD: usize = 30;
const BASIS_SWEET_SPOT: (usize, usize) = (10, 50);
const DISTINGUISH_THRESHOLD: f64 = 0.3;

#[derive(Debug)]
pub struct Node {
    pub id: String,
    pub cluster_count: usize,
    pub depth: usize,
    pub avg_pairs: f64,
}

pub fn recommended_technique(node: &Node, similarity: f64) -> &'static str {
    // Rule 1: Large clusters at shallow depths -> FFT
    if node.cluster_count >= FFT_THRESHOLD && node.depth < 3 {
        return "fft";
    }

    // Rule 2: Medium clusters -> basis_k8
    if node.cluster_count >= BASIS_SWEET_SPOT.0 &&
       node.cluster_count <= BASIS_SWEET_SPOT.1 &&
       node.depth >= 1 && node.avg_pairs >= 2.0 {
        return "basis_k8";
    }

    // Rule 3: Already distinguishable -> baseline
    if similarity < DISTINGUISH_THRESHOLD {
        return "baseline";
    }

    // Rule 4: Small clusters -> baseline
    if node.cluster_count < 5 {
        return "baseline";
    }

    // Fallback
    if node.cluster_count >= 5 { "basis_k4" } else { "baseline" }
}

pub fn refinement_needed(node: &Node, similarity: f64) -> bool {
    node.cluster_count > 10 && node.depth < 4 && similarity > 0.7
}
```

## Policy Variations

Users may want different policies for different use cases. Here are common variations:

### 1. Speed-Optimized Policy

Minimize training time, accept slightly lower accuracy:

```prolog
%% Aggressive: FFT everywhere possible
recommended_technique(NodeId, fft) :-
    node(NodeId, ClusterCount, _, _, _),
    ClusterCount >= 10.  % Lower threshold

recommended_technique(NodeId, baseline) :-
    node(NodeId, ClusterCount, _, _, _),
    ClusterCount < 10.

%% Never refine - single pass only
refinement_needed(_) :- fail.
```

### 2. Accuracy-Optimized Policy

Maximize accuracy, accept higher training cost:

```prolog
%% Use basis methods more aggressively
recommended_technique(NodeId, basis_k16) :-
    node(NodeId, ClusterCount, _, Depth, AvgPairs),
    ClusterCount >= 20,
    ClusterCount =< 100,
    Depth >= 1,
    AvgPairs >= 3.

%% Refine even moderately confusable segments
refinement_needed(NodeId) :-
    node(NodeId, ClusterCount, _, Depth, _),
    ClusterCount > 5,
    Depth < 5,
    similarity_score(NodeId, Score),
    Score > 0.5.  % Lower threshold
```

### 3. Resource-Constrained Policy

For limited compute environments:

```prolog
%% Only FFT at root, baseline everywhere else
recommended_technique(root, fft).

recommended_technique(NodeId, baseline) :-
    NodeId \= root.

%% No refinement
refinement_needed(_) :- fail.
```

### 4. Interpretability-Focused Policy

When you need to understand the learned projections:

```prolog
%% Prefer basis methods for interpretable structure
recommended_technique(NodeId, basis_k4) :-
    node(NodeId, ClusterCount, _, _, _),
    ClusterCount >= 5,
    ClusterCount < 20.

recommended_technique(NodeId, basis_k8) :-
    node(NodeId, ClusterCount, _, _, _),
    ClusterCount >= 20.

%% No FFT - harder to interpret frequency filtering
recommended_technique(NodeId, baseline) :-
    node(NodeId, ClusterCount, _, _, _),
    ClusterCount < 5.
```

## Integration with Smoothing Execution

The compiled policy integrates with the smoothing execution pipeline:

```
┌─────────────────────────────────────────────────────────────┐
│                    Smoothing Pipeline                        │
├─────────────────────────────────────────────────────────────┤
│                                                              │
│  1. Build tree from FFT ordering                            │
│     └── MST + DFS creates segments                          │
│                                                              │
│  2. Compute distinguishability scores                        │
│     └── similarity_score per node                           │
│                                                              │
│  3. Query compiled policy for each node                      │
│     └── recommended_technique(node) → technique             │
│     └── refinement_needed(node) → bool                      │
│                                                              │
│  4. Execute plan                                             │
│     └── Train projector per node                            │
│     └── Apply soft constraints (non-FFT only)               │
│                                                              │
│  5. Inference                                                │
│     └── Route to segment                                    │
│     └── Blend parent + child projections                    │
│                                                              │
└─────────────────────────────────────────────────────────────┘
```

## Implementation Plan

### Phase 1: Policy Specification (Done)

- [x] Define `smoothing_policy.pl` with core rules
- [x] Manual Python translation for testing
- [x] Validate logic with benchmark

### Phase 2: UnifyWeaver Integration

- [ ] Add smoothing policy as compilation target
- [ ] Define node/similarity input schema
- [ ] Generate Python from Prolog
- [ ] Test equivalence with manual translation

### Phase 3: Multi-Target Compilation

- [ ] Generate Go code for federation layer
- [ ] Generate Rust code for performance-critical paths
- [ ] Ensure consistent behavior across targets

### Phase 4: Policy Customization

- [ ] Support user-defined policies
- [ ] Policy inheritance/composition
- [ ] Runtime policy switching

## Open Questions

1. **Dynamic thresholds**: Should thresholds adapt based on data characteristics?

2. **Learning policies**: Could we learn the policy from benchmark results?

3. **Cost modeling**: Should the policy consider actual timing, not just complexity?

4. **Incremental updates**: How does the policy handle new clusters added to existing segments?

## Related Files

- `src/unifyweaver/core/lda_smoothing_policy.pl` - Prolog policy definition
- `src/unifyweaver/targets/python_runtime/smoothing_planner.py` - Execution bridge
- `src/unifyweaver/targets/python_runtime/fft_smoothing.py` - FFT implementation
- `src/unifyweaver/targets/python_runtime/smoothing_basis.py` - Basis implementation
- `docs/proposals/LDA_SMOOTHING_THEORY.md` - Theoretical foundations
- `docs/proposals/CROSS_CLUSTER_SMOOTHING.md` - Implementation overview

## Conclusion

The smoothing policy is a natural fit for UnifyWeaver's declarative-to-imperative compilation model. By expressing the technique selection logic in Prolog, we gain:

1. **Clarity**: Rules are readable and modifiable
2. **Portability**: Compile to any target language
3. **Consistency**: Single source of truth
4. **Flexibility**: Easy to swap policies for different use cases

The current manual Python translation validates the approach; UnifyWeaver compilation will automate it.
